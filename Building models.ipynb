{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'df_stanford_real_features.csv'\n",
    "#dataset = 'df_fifa_features_all.csv'\n",
    "\n",
    "random_seed =1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading and preparing datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(dataset)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = df['labels']\n",
    "features = df.drop(columns = ['labels'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Balance of classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "sns.countplot(labels,label=\"Count\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove Rows With Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.invert(df.isnull().any(axis=1))\n",
    "labels = labels[np.invert(features.isnull().any(axis=1))]\n",
    "\n",
    "# drop rows with missing values\n",
    "features.dropna(inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Training and Test Sets and Apply Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = features\n",
    "y = labels\n",
    "\n",
    "y = y[np.invert(X.isnull().any(axis=1)).values]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/preprocessing/data.py:617: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/base.py:462: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:7: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y,random_state=random_seed)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Logistic regression classifier on training set: 0.61\n",
      "Accuracy of Logistic regression classifier on test set: 0.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:459: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "print('Accuracy of Logistic regression classifier on training set: {:.2f}'\n",
    "     .format(logreg.score(X_train, y_train)))\n",
    "\n",
    "print('Accuracy of Logistic regression classifier on test set: {:.2f}'\n",
    "     .format(logreg.score(X_test, y_test)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of SVM classifier on training set: 0.73\n",
      "Accuracy of SVM classifier on test set: 0.53\n"
     ]
    }
   ],
   "source": [
    "svm = SVC()\n",
    "svm.fit(X_train, y_train)\n",
    "\n",
    "print('Accuracy of SVM classifier on training set: {:.2f}'\n",
    "     .format(svm.score(X_train, y_train)))\n",
    "print('Accuracy of SVM classifier on test set: {:.2f}'\n",
    "     .format(svm.score(X_test, y_test)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's try to convert the label to dummy variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Logistic regression classifier D on training set: 0.74\n",
      "Accuracy of Logistic regression classifier D on test set: 0.64\n",
      "Accuracy of Logistic regression classifier H on training set: 0.70\n",
      "Accuracy of Logistic regression classifier H on test set: 0.63\n",
      "Accuracy of Logistic regression classifier D on training set: 0.76\n",
      "Accuracy of Logistic regression classifier D on test set: 0.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/preprocessing/data.py:323: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/preprocessing/data.py:323: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/preprocessing/data.py:323: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "y_A = pd.get_dummies(y)['A']\n",
    "X_train, X_test, y_train_A, y_test_A = train_test_split(X, y_A,random_state=random_seed)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, y_train_A)\n",
    "\n",
    "print('Accuracy of Logistic regression classifier D on training set: {:.2f}'\n",
    "     .format(logreg.score(X_train, y_train_A)))\n",
    "\n",
    "print('Accuracy of Logistic regression classifier D on test set: {:.2f}'\n",
    "     .format(logreg.score(X_test, y_test_A)))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "y_H = pd.get_dummies(y)['H']\n",
    "X_train, X_test, y_train_H, y_test_H = train_test_split(X, y_H,random_state=random_seed)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, y_train_H)\n",
    "\n",
    "print('Accuracy of Logistic regression classifier H on training set: {:.2f}'\n",
    "     .format(logreg.score(X_train, y_train_H)))\n",
    "\n",
    "print('Accuracy of Logistic regression classifier H on test set: {:.2f}'\n",
    "     .format(logreg.score(X_test, y_test_H)))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "y_D = pd.get_dummies(y)['D']\n",
    "X_train, X_test, y_train_D, y_test_D = train_test_split(X, y_D,random_state=random_seed)\n",
    "\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, y_train_D)\n",
    "\n",
    "print('Accuracy of Logistic regression classifier D on training set: {:.2f}'\n",
    "     .format(logreg.score(X_train, y_train_D)))\n",
    "\n",
    "print('Accuracy of Logistic regression classifier D on test set: {:.2f}'\n",
    "     .format(logreg.score(X_test, y_test_D)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Logistic regression classifier D on training set: 0.70\n",
      "Accuracy of Logistic regression classifier D on test set: 0.63\n",
      "Accuracy of Logistic regression classifier H on training set: 0.69\n",
      "Accuracy of Logistic regression classifier H on test set: 0.67\n",
      "Accuracy of Logistic regression classifier D on training set: 0.76\n",
      "Accuracy of Logistic regression classifier D on test set: 0.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/preprocessing/data.py:323: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/preprocessing/data.py:323: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/preprocessing/data.py:323: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "y_A = pd.get_dummies(y)['A']\n",
    "X_train, X_test, y_train_A, y_test_A = train_test_split(X, y_A,random_state=random_seed)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "logreg = SVC()\n",
    "logreg.fit(X_train, y_train_A)\n",
    "\n",
    "print('Accuracy of Logistic regression classifier D on training set: {:.2f}'\n",
    "     .format(logreg.score(X_train, y_train_A)))\n",
    "\n",
    "print('Accuracy of Logistic regression classifier D on test set: {:.2f}'\n",
    "     .format(logreg.score(X_test, y_test_A)))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "y_H = pd.get_dummies(y)['H']\n",
    "X_train, X_test, y_train_H, y_test_H = train_test_split(X, y_H,random_state=random_seed)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "logreg = SVC()\n",
    "logreg.fit(X_train, y_train_H)\n",
    "\n",
    "print('Accuracy of Logistic regression classifier H on training set: {:.2f}'\n",
    "     .format(logreg.score(X_train, y_train_H)))\n",
    "\n",
    "print('Accuracy of Logistic regression classifier H on test set: {:.2f}'\n",
    "     .format(logreg.score(X_test, y_test_H)))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "y_D = pd.get_dummies(y)['D']\n",
    "X_train, X_test, y_train_D, y_test_D = train_test_split(X, y_D,random_state=random_seed)\n",
    "\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "logreg = SVC()\n",
    "logreg.fit(X_train, y_train_D)\n",
    "\n",
    "print('Accuracy of Logistic regression classifier D on training set: {:.2f}'\n",
    "     .format(logreg.score(X_train, y_train_D)))\n",
    "\n",
    "print('Accuracy of Logistic regression classifier D on test set: {:.2f}'\n",
    "     .format(logreg.score(X_test, y_test_D)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
