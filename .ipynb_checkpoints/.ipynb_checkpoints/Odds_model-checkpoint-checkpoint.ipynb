{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "\n",
    "\n",
    "# Create db connection.\n",
    "cnx = sqlite3.connect('database.sqlite')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "DatabaseError",
     "evalue": "Execution failed on sql 'SELECT * FROM League': no such table: League",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/pandas/io/sql.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1377\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1378\u001b[0;31m                 \u001b[0mcur\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1379\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mcur\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOperationalError\u001b[0m: no such table: League",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mDatabaseError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-e871ee5b59bf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_league\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_sql_query\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"SELECT * FROM League\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcnx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mseasons\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'2015/2016'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'2014/2015'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'2013/2014'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'2012/2013'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'2011/2012'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'2010/2011'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'2009/2010'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mleagues_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m21518\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1729\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/pandas/io/sql.py\u001b[0m in \u001b[0;36mread_sql_query\u001b[0;34m(sql, con, index_col, coerce_float, params, parse_dates, chunksize)\u001b[0m\n\u001b[1;32m    312\u001b[0m     return pandas_sql.read_query(\n\u001b[1;32m    313\u001b[0m         \u001b[0msql\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindex_col\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoerce_float\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcoerce_float\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 314\u001b[0;31m         parse_dates=parse_dates, chunksize=chunksize)\n\u001b[0m\u001b[1;32m    315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/pandas/io/sql.py\u001b[0m in \u001b[0;36mread_query\u001b[0;34m(self, sql, index_col, coerce_float, params, parse_dates, chunksize)\u001b[0m\n\u001b[1;32m   1411\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1412\u001b[0m         \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_convert_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msql\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1413\u001b[0;31m         \u001b[0mcursor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1414\u001b[0m         \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcol_desc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcol_desc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcursor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdescription\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1415\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/pandas/io/sql.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1388\u001b[0m             ex = DatabaseError(\n\u001b[1;32m   1389\u001b[0m                 \"Execution failed on sql '%s': %s\" % (args[0], exc))\n\u001b[0;32m-> 1390\u001b[0;31m             \u001b[0mraise_with_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1391\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1392\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/pandas/compat/__init__.py\u001b[0m in \u001b[0;36mraise_with_traceback\u001b[0;34m(exc, traceback)\u001b[0m\n\u001b[1;32m    402\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtraceback\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mEllipsis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    403\u001b[0m             \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraceback\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 404\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraceback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    405\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m     \u001b[0;31m# this version of raise is a syntax error in Python 3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/pandas/io/sql.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1376\u001b[0m                 \u001b[0mcur\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1377\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1378\u001b[0;31m                 \u001b[0mcur\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1379\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mcur\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1380\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDatabaseError\u001b[0m: Execution failed on sql 'SELECT * FROM League': no such table: League"
     ]
    }
   ],
   "source": [
    "df_league = pd.read_sql_query(\"SELECT * FROM League\", cnx) \n",
    "\n",
    "seasons = ['2015/2016','2014/2015','2013/2014','2012/2013','2011/2012','2010/2011','2009/2010']\n",
    "leagues_id = [21518,1729]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_league"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Taking a look to the Match Table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all we filter just the games of the desire league and season"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning names of teams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import stringdist\n",
    "\n",
    "# Normalize names \n",
    "def normalize_team_names(y):\n",
    "    teams = []\n",
    "    for t in list(y):\n",
    "        tt = t.lower().split()\n",
    "        rem = []\n",
    "        cont=0\n",
    "        #print(tt)\n",
    "        for el in tt:\n",
    "            cont +=1\n",
    "            if el in ['athletico','atletico','athlético','atlético','atl','ath','athletic']: \n",
    "                if cont < len(tt):\n",
    "                    tt[cont]='atl'+tt[cont]\n",
    "            if el in ['manchester','man','sporting','sp','deportivo','la','de','real','fc','cf','ud','las','cd','balompié','rc','de','athletico','atletico','athlético','atlético','atl','ath','athletic']:\n",
    "                rem.append(el)\n",
    "            \n",
    "                #print(tt)\n",
    "        if rem != []:\n",
    "            for r in rem:\n",
    "                tt.remove(r)\n",
    "        \n",
    "        if len(tt)>1:\n",
    "            if len(tt[0])>len(tt[1]):\n",
    "                t = tt[0]\n",
    "            else:\n",
    "                t = tt[1]\n",
    "        else:\n",
    "            t=tt[0]\n",
    "        #print(t)  \n",
    "        teams.append(t)\n",
    "    return teams\n",
    "\n",
    "#Change name x for the most similar name in the teams_normalized list.\n",
    "def func(x,teams_normalized):\n",
    "    dist =0\n",
    "    distmin=10\n",
    "    xt = x.lower().split()\n",
    "    rem = []\n",
    "    cont=0\n",
    "    for el in xt:\n",
    "        cont +=1\n",
    "        if el in ['athletico','atletico','athlético','atlético','atl','ath','athletic']:\n",
    "            if cont < len(xt):\n",
    "                xt[cont]='atl'+xt[cont]\n",
    "        if el in ['manchester','man','sporting','sp','deportivo','la','de','real','fc','cf','ud','las','cd','balompié','rc','de','athletico','atletico','athlético','atlético','atl','ath','athletic']:\n",
    "            rem.append(el)\n",
    "    if rem != []:\n",
    "        for r in rem:\n",
    "                xt.remove(r)\n",
    "                \n",
    "\n",
    "\n",
    "    if len(xt)>1:\n",
    "        if len(xt[0])>len(xt[1]):\n",
    "            x = xt[0]\n",
    "        else:\n",
    "            x = xt[1]\n",
    "    else:\n",
    "        x=xt[0]\n",
    "\n",
    "    \n",
    "    for t in list(teams_normalized):\n",
    "        dist = stringdist.levenshtein(x, t)\n",
    "        #print(t)\n",
    "        if dist < distmin:\n",
    "            #print('................')\n",
    "            #print(x)\n",
    "            #print(t)\n",
    "            #print(dist)\n",
    "            #print('................')\n",
    "            distmin = dist\n",
    "            team =t\n",
    "    return team\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_standard_team_names(cnx, league_id, season):\n",
    "\n",
    "    #.......... df_matches ..........\n",
    "    \n",
    "    #Read matches from the season and league specified.\n",
    "    df_matches = pd.read_sql_query(\"SELECT * FROM Match WHERE league_id = (?) AND season = (?)\", cnx, params=(league_id,season,)) \n",
    "    print(f'The shape of df_matches of league:{league_id} and season:{season} is: {df_matches.shape}')\n",
    "\n",
    "    #Drop columns with not useful information (html text), we will get this information from another dataset from football-data.co.uk\n",
    "    df_matches = df_matches.drop(columns=['goal', 'shoton', 'shotoff','foulcommit', 'card', 'cross', 'corner', 'possession'])\n",
    "\n",
    "    #Convert types\n",
    "    df_matches['date'] = pd.to_datetime(df_matches['date'])\n",
    "    df_matches['date'] = pd.to_datetime(df_matches['date'],format='%Y%m%d')\n",
    "    df_matches['stage'] = df_matches['stage'].astype(int)\n",
    "    \n",
    "   #To merge data with the other dataset we need a common team id between both datasets. We are going to create a unique string identifier for team names named team_name_id.\n",
    "    \n",
    "    \n",
    "    #In the df_matches we will first include a column with the name of the team extracted from the Team table by means of the team_api_id.\n",
    "    df_Teams = pd.read_sql_query(\"SELECT * FROM Team \", cnx)\n",
    "    df_Teams.head()\n",
    "    \n",
    "\n",
    "    # Manually change some names due its difficulty to be treated for our string name procedure.\n",
    "    df_Teams.loc[df_Teams['team_long_name']=='Athletic Club de Bilbao','team_long_name'] = 'Athletic Bilbao'\n",
    "    df_Teams.loc[df_Teams['team_long_name']=='Real Sporting de Gijón','team_long_name'] = 'Sporting Gijon'\n",
    "    \n",
    "    df_Teams.loc[df_Teams['team_long_name']=='West Bromwich Albion','team_long_name'] = 'West Brom'\n",
    "    df_Teams.loc[df_Teams['team_long_name']=='West Ham United','team_long_name'] = 'West Ham'\n",
    "    df_Teams.loc[df_Teams['team_long_name']=='Queens Park Rangers','team_long_name'] = 'QPR'\n",
    "    df_Teams.loc[df_Teams['team_long_name']=='Stoke City','team_long_name'] = 'Stoke'\n",
    "    df_Teams.loc[df_Teams['team_long_name']=='Hull City','team_long_name'] = 'Hull'\n",
    "    df_Teams.loc[df_Teams['team_long_name']=='Bolton Wanderers','team_long_name'] = 'Bolton'\n",
    "    df_Teams.loc[df_Teams['team_long_name']=='Wolverhampton Wanderers', 'team_long_name'] = 'Wolves'\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    #First we normalize the names of the teams\n",
    "    teams_normalized = normalize_team_names(df_Teams['team_long_name'])\n",
    "    \n",
    "    #Now we normalize the names of df_Teams \n",
    "    df_Teams['team_name_id']= df_Teams['team_long_name'].apply(lambda x: func(x,teams_normalized))\n",
    "\n",
    "    \n",
    "    #Now we will have to include names of the teams into de df_matches dataframe, for this we have to merge df_matches with df_Teams on the \"team_api_id\".\n",
    "    #Since df_matches just have names of the 'home_team_api_id' and 'away_team_api_id', we will add a new column referring the corresponding teams as 'home_team_name_id' and 'away_team_name_id'.\n",
    "    df_matches['home_team_name_id']=df_matches.merge(df_Teams[['team_api_id','team_name_id']], left_on='home_team_api_id', right_on='team_api_id',how='left')['team_name_id']\n",
    "    df_matches['away_team_name_id']=df_matches.merge(df_Teams[['team_api_id','team_name_id']], left_on='away_team_api_id', right_on='team_api_id',how='left')['team_name_id']\n",
    "\n",
    "    #We finally have the df_matches with the Match Table information but with the home_tema_name_id and away_team_name_id which will be useful to create a common id between the two csv that we want to merge.\n",
    "    \n",
    "    #print(df_Teams)\n",
    "    \n",
    "\n",
    "    \n",
    "    #.......... footballdata ..........\n",
    "    \n",
    "    #Read matches from the season and league specified.\n",
    "    location_to_file = 'data/'\n",
    "    season_footdata = season.replace('/','_').replace('20','') \n",
    "    df_footballdata = pd.read_csv(location_to_file+'{0}_{1}.csv'.format(league_id,season_footdata))   \n",
    "    print(f'The shape of df_footballdata of league:{league_id} and season:{season_footdata} is: {df_footballdata.shape}')\n",
    "  \n",
    "    #Convert types    \n",
    "    df_footballdata['date'] = pd.to_datetime(df_footballdata['Date'])\n",
    "    df_footballdata['date'] = pd.to_datetime(df_footballdata['date'], format='%Y%m%d')\n",
    "\n",
    "    \n",
    "    #Creating same names for teams as the other dataset\n",
    "    df_footballdata['home_team_name_id'] = df_footballdata['HomeTeam'].apply(lambda x: func(x,teams_normalized))\n",
    "    df_footballdata['away_team_name_id'] = df_footballdata['AwayTeam'].apply(lambda x: func(x,teams_normalized))\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    #Creating common match identifier for both datasets (uid)\n",
    "    df_footballdata['uid']= df_footballdata['home_team_name_id']+df_footballdata['away_team_name_id']\n",
    "    df_matches['uid']= df_matches['home_team_name_id']+df_matches['away_team_name_id']\n",
    "    \n",
    "    return df_matches, df_footballdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = []\n",
    "for league_id in leagues_id:\n",
    "    for season in seasons:\n",
    "        df_matches, df_footballdata = convert_to_standard_team_names(cnx, league_id, season)\n",
    "        datasets.append(df_matches.loc[:, :])\n",
    "        \n",
    "df_matches_all_seasons_leagues = pd.concat(datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Labels\n",
    "\n",
    "def res(x,x1):\n",
    "    if x > x1:\n",
    "        return 'H'\n",
    "    elif x < x1:\n",
    "        return 'A'\n",
    "    else:\n",
    "        return 'D'\n",
    "    \n",
    "labels = df_matches_all_seasons_leagues.apply(lambda x: res(x['home_team_goal'],x['away_team_goal']), axis =1 )\n",
    "df_matches_all_seasons_leagues['labels'] = labels\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Simplest model\n",
    "\n",
    "def predict_lowest_odd(H,D,A):\n",
    "    if H <= D and H <= A:\n",
    "        return 'H'\n",
    "    elif D <= H and D <= A:\n",
    "        return 'D'\n",
    "    elif A <= H and A <= D:\n",
    "        return 'A'\n",
    "        \n",
    "predictions = df_matches_all_seasons_leagues.apply(lambda x: predict_lowest_odd(x['B365H'],x['B365D'],x['B365A']), axis =1 )\n",
    "\n",
    "\n",
    "accuracy_score(labels, predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_matches_all_seasons_leagues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
