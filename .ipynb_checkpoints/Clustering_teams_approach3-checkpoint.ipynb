{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "\n",
    "\n",
    "# Create db connection.\n",
    "cnx = sqlite3.connect('data/database.sqlite')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "seasons = ['2015/2016']\n",
    "leagues_id = [21518]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of df_matches of league:21518 and season:2015/2016 is: (380, 115)\n",
      "The shape of df_footballdata of league:21518 and season:15_16 is: (380, 64)\n",
      "df_complete_league_year shape: (380, 128)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/pandas/core/frame.py:3140: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self[k1] = value[k2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of df_matches of league:21518 and season:2014/2015 is: (380, 115)\n",
      "The shape of df_footballdata of league:21518 and season:14_15 is: (380, 67)\n",
      "df_complete_league_year shape: (380, 128)\n"
     ]
    }
   ],
   "source": [
    "## Cleaning names of teams\n",
    "\n",
    "import stringdist\n",
    "\n",
    "# Normalize names \n",
    "def normalize_team_names(y):\n",
    "    teams = []\n",
    "    for t in list(y):\n",
    "        tt = t.lower().split()\n",
    "        rem = []\n",
    "        cont=0\n",
    "        #print(tt)\n",
    "        for el in tt:\n",
    "            cont +=1\n",
    "            if el in ['athletico','atletico','athlético','atlético','atl','ath','athletic']: \n",
    "                if cont < len(tt):\n",
    "                    tt[cont]='atl'+tt[cont]\n",
    "            if el in ['manchester','man','sporting','sp','deportivo','la','de','real','fc','cf','ud','las','cd','balompié','rc','de','athletico','atletico','athlético','atlético','atl','ath','athletic']:\n",
    "                rem.append(el)\n",
    "            \n",
    "                #print(tt)\n",
    "        if rem != []:\n",
    "            for r in rem:\n",
    "                tt.remove(r)\n",
    "        \n",
    "        if len(tt)>1:\n",
    "            if len(tt[0])>len(tt[1]):\n",
    "                t = tt[0]\n",
    "            else:\n",
    "                t = tt[1]\n",
    "        else:\n",
    "            t=tt[0]\n",
    "        #print(t)  \n",
    "        teams.append(t)\n",
    "    return teams\n",
    "\n",
    "#Change name x for the most similar name in the teams_normalized list.\n",
    "def func(x,teams_normalized):\n",
    "    dist =0\n",
    "    distmin=10\n",
    "    xt = x.lower().split()\n",
    "    rem = []\n",
    "    cont=0\n",
    "    for el in xt:\n",
    "        cont +=1\n",
    "        if el in ['athletico','atletico','athlético','atlético','atl','ath','athletic']:\n",
    "            if cont < len(xt):\n",
    "                xt[cont]='atl'+xt[cont]\n",
    "        if el in ['manchester','man','sporting','sp','deportivo','la','de','real','fc','cf','ud','las','cd','balompié','rc','de','athletico','atletico','athlético','atlético','atl','ath','athletic']:\n",
    "            rem.append(el)\n",
    "    if rem != []:\n",
    "        for r in rem:\n",
    "                xt.remove(r)\n",
    "                \n",
    "\n",
    "\n",
    "    if len(xt)>1:\n",
    "        if len(xt[0])>len(xt[1]):\n",
    "            x = xt[0]\n",
    "        else:\n",
    "            x = xt[1]\n",
    "    else:\n",
    "        x=xt[0]\n",
    "\n",
    "    \n",
    "    for t in list(teams_normalized):\n",
    "        dist = stringdist.levenshtein(x, t)\n",
    "        #print(t)\n",
    "        if dist < distmin:\n",
    "            #print('................')\n",
    "            #print(x)\n",
    "            #print(t)\n",
    "            #print(dist)\n",
    "            #print('................')\n",
    "            distmin = dist\n",
    "            team =t\n",
    "    return team\n",
    "\n",
    "\n",
    "\n",
    "def convert_to(df,type_to_convert, all_categorical = False,columns = 'None'):\n",
    " \n",
    "    if all_categorical == True:\n",
    "        categoric_types = df.select_dtypes(include=['object','category']).columns\n",
    "        if categoric_types.empty:\n",
    "            print('No object types in the dataframe to be converted')\n",
    "            return df\n",
    "        else:\n",
    "            if 'labels' in categoric_types:\n",
    "                categoric_types.remove('labels')\n",
    "            df[categoric_types] = df[categoric_types].astype('category')\n",
    "            columns = categoric_types\n",
    "        \n",
    "    else:\n",
    "        df[columns] = df[columns].astype('category')\n",
    "        \n",
    "        \n",
    "    if type_to_convert == 'labelling':\n",
    "        for column in columns:\n",
    "            df[column] = df[column].cat.codes\n",
    "    elif type_to_convert == 'onehot':\n",
    "        for column in columns:\n",
    "            print(columns)\n",
    "            df= pd.get_dummies(df, columns=[column])             \n",
    "      \n",
    "    return df\n",
    "\n",
    "def convert_to_standard_team_names(cnx, league_id, season):\n",
    "\n",
    "    #.......... df_matches ..........\n",
    "    \n",
    "    #Read matches from the season and league specified.\n",
    "    df_matches = pd.read_sql_query(\"SELECT * FROM Match WHERE league_id = (?) AND season = (?)\", cnx, params=(league_id,season,)) \n",
    "    print(f'The shape of df_matches of league:{league_id} and season:{season} is: {df_matches.shape}')\n",
    "\n",
    "    #Drop columns with not useful information (html text), we will get this information from another dataset from football-data.co.uk\n",
    "    df_matches = df_matches.drop(columns=['goal', 'shoton', 'shotoff','foulcommit', 'card', 'cross', 'corner', 'possession'])\n",
    "\n",
    "    #Convert types\n",
    "    df_matches['date'] = pd.to_datetime(df_matches['date'])\n",
    "    df_matches['date'] = pd.to_datetime(df_matches['date'],format='%Y%m%d')\n",
    "    df_matches['stage'] = df_matches['stage'].astype(int)\n",
    "    \n",
    "   #To merge data with the other dataset we need a common team id between both datasets. We are going to create a unique string identifier for team names named team_name_id.\n",
    "    \n",
    "    \n",
    "    #In the df_matches we will first include a column with the name of the team extracted from the Team table by means of the team_api_id.\n",
    "    df_Teams = pd.read_sql_query(\"SELECT * FROM Team \", cnx)\n",
    "    df_Teams.head()\n",
    "    \n",
    "\n",
    "    # Manually change some names due its difficulty to be treated for our string name procedure.\n",
    "    df_Teams.loc[df_Teams['team_long_name']=='Athletic Club de Bilbao','team_long_name'] = 'Athletic Bilbao'\n",
    "    df_Teams.loc[df_Teams['team_long_name']=='Real Sporting de Gijón','team_long_name'] = 'Sporting Gijon'\n",
    "    \n",
    "    df_Teams.loc[df_Teams['team_long_name']=='West Bromwich Albion','team_long_name'] = 'West Brom'\n",
    "    df_Teams.loc[df_Teams['team_long_name']=='West Ham United','team_long_name'] = 'West Ham'\n",
    "    df_Teams.loc[df_Teams['team_long_name']=='Queens Park Rangers','team_long_name'] = 'QPR'\n",
    "    df_Teams.loc[df_Teams['team_long_name']=='Stoke City','team_long_name'] = 'Stoke'\n",
    "    df_Teams.loc[df_Teams['team_long_name']=='Hull City','team_long_name'] = 'Hull'\n",
    "    df_Teams.loc[df_Teams['team_long_name']=='Bolton Wanderers','team_long_name'] = 'Bolton'\n",
    "    df_Teams.loc[df_Teams['team_long_name']=='Wolverhampton Wanderers', 'team_long_name'] = 'Wolves'\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    #First we normalize the names of the teams\n",
    "    teams_normalized = normalize_team_names(df_Teams['team_long_name'])\n",
    "    \n",
    "    #Now we normalize the names of df_Teams \n",
    "    df_Teams['team_name_id']= df_Teams['team_long_name'].apply(lambda x: func(x,teams_normalized))\n",
    "\n",
    "    \n",
    "    #Now we will have to include names of the teams into de df_matches dataframe, for this we have to merge df_matches with df_Teams on the \"team_api_id\".\n",
    "    #Since df_matches just have names of the 'home_team_api_id' and 'away_team_api_id', we will add a new column referring the corresponding teams as 'home_team_name_id' and 'away_team_name_id'.\n",
    "    df_matches['home_team_name_id']=df_matches.merge(df_Teams[['team_api_id','team_name_id']], left_on='home_team_api_id', right_on='team_api_id',how='left')['team_name_id']\n",
    "    df_matches['away_team_name_id']=df_matches.merge(df_Teams[['team_api_id','team_name_id']], left_on='away_team_api_id', right_on='team_api_id',how='left')['team_name_id']\n",
    "\n",
    "    #We finally have the df_matches with the Match Table information but with the home_tema_name_id and away_team_name_id which will be useful to create a common id between the two csv that we want to merge.\n",
    "    \n",
    "    #print(df_Teams)\n",
    "    \n",
    "\n",
    "    \n",
    "    #.......... footballdata ..........\n",
    "    \n",
    "    #Read matches from the season and league specified.\n",
    "    location_to_file = 'data/'\n",
    "    season_footdata = season.replace('/','_').replace('20','') \n",
    "    df_footballdata = pd.read_csv(location_to_file+'{0}_{1}.csv'.format(league_id,season_footdata))   \n",
    "    print(f'The shape of df_footballdata of league:{league_id} and season:{season_footdata} is: {df_footballdata.shape}')\n",
    "  \n",
    "    #Convert types    \n",
    "    df_footballdata['date'] = pd.to_datetime(df_footballdata['Date'])\n",
    "    df_footballdata['date'] = pd.to_datetime(df_footballdata['date'], format='%Y%m%d')\n",
    "\n",
    "    \n",
    "    #Creating same names for teams as the other dataset\n",
    "    df_footballdata['home_team_name_id'] = df_footballdata['HomeTeam'].apply(lambda x: func(x,teams_normalized))\n",
    "    df_footballdata['away_team_name_id'] = df_footballdata['AwayTeam'].apply(lambda x: func(x,teams_normalized))\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    #Creating common match identifier for both datasets (uid)\n",
    "    df_footballdata['uid']= df_footballdata['home_team_name_id']+df_footballdata['away_team_name_id']\n",
    "    df_matches['uid']= df_matches['home_team_name_id']+df_matches['away_team_name_id']\n",
    "    \n",
    "    return df_matches, df_footballdata\n",
    "\n",
    "def merge_matchtable_footballdata(season,league_id):\n",
    "    \n",
    "    df_matches, df_footballdata = convert_to_standard_team_names(cnx, league_id, season)\n",
    "    \n",
    "#     print((df_matches[['home_team_name_id','away_team_name_id','uid']]))\n",
    "     \n",
    "#     print((df_footballdata[['home_team_name_id','away_team_name_id']]))\n",
    "\n",
    "#     print((df_matches['uid'].sort_values(ascending=True)))\n",
    "#     print((df_footballdata['uid'].sort_values(ascending=True)))\n",
    "    \n",
    "    if len(set(df_matches['uid']).symmetric_difference(set(df_footballdata['uid']))) > 0:\n",
    "        print('Names of uid of both datasets do not match.')\n",
    "        print('CAUTION!!!! THE FOLLOWING NAMES HAVE DIFFERENT SPELLING IN THE TWO DATASETS: ',\n",
    "              set(df_matches['uid']).symmetric_difference(set(df_footballdata['uid'])))\n",
    "    \n",
    "    # Merging both datasets\n",
    "    df_complete_league_year = pd.merge(df_matches, df_footballdata[['FTHG', 'FTAG', 'FTR', 'HTHG', 'HTAG',\n",
    "       'HTR', 'HS', 'AS', 'HST', 'AST', 'HF', 'AF', 'HC', 'AC', 'HY','AY', 'HR', 'AR','uid']], on='uid', how='inner')\n",
    "    \n",
    "    print(f'df_complete_league_year shape: {df_complete_league_year.shape}')\n",
    "\n",
    "    \n",
    "    \n",
    "    # Implementing models with Real Data as the guys from Stanford suggest.\n",
    "    # We create the dataset as it is stated at: \n",
    "    # *Shin, JongHo and Robert Gasparyan. “A novel way to Soccer Match Prediction.” (2014).*\n",
    "    \n",
    "    #Sort per date.\n",
    "    df_complete_league_year['date'] = pd.to_datetime(df_complete_league_year['date'])\n",
    "    df_complete_league_year=df_complete_league_year.sort_values(by='date')\n",
    "\n",
    "    #We keep just the data need it for this.\n",
    "    df_matches_info = df_complete_league_year[['id','uid','date','stage','home_team_name_id','away_team_name_id','FTHG', 'FTAG', 'FTR', 'HTHG', 'HTAG',\n",
    "       'HTR', 'HS', 'AS', 'HST', 'AST', 'HF', 'AF', 'HC', 'AC', 'HY','AY', 'HR', 'AR']]  \n",
    "    df_matches_info[['FTHG', 'FTAG', 'HTHG', 'HTAG', 'HS', 'AS', 'HST', 'AST', 'HF', 'AF','HC', 'AC', 'HY','AY', 'HR', 'AR']] = df_matches_info.loc[:,['FTHG', 'FTAG', 'HTHG', 'HTAG', 'HS', 'AS', 'HST', 'AST', 'HF', 'AF','HC', 'AC', 'HY','AY', 'HR', 'AR']].astype(float)\n",
    "\n",
    "    \n",
    "    #Creating a column for the labels\n",
    "    labels = df_matches_info[\"FTR\"]\n",
    "    df_matches_info = pd.get_dummies(df_matches_info, columns=[\"FTR\", \"HTR\"])\n",
    "    df_matches_info['labels'] = labels\n",
    "\n",
    "    #Creating the mean of each columns taking the past mathces (rows)\n",
    "    df_stanford_model = df_matches_info.copy()\n",
    "    df_stanford_model[['FTHG_mean','HTHG_mean','HS_mean','HST_mean','HF_mean','HC_mean','HY_mean','HR_mean','H_FTR_A_mean','H_FTR_D_mean','H_FTR_H_mean','H_HTR_A_mean','H_HTR_D_mean','H_HTR_H_mean']]= df_stanford_model.groupby('home_team_name_id')['FTHG','HTHG','HS','HST','HF','HC','HY','HR','FTR_A','FTR_D','FTR_H','HTR_A','HTR_D','HTR_H'].apply(lambda x:x.expanding().mean().shift())\n",
    "    df_stanford_model[['FTAG_mean','HTAG_mean','AS_mean','AST_mean','AF_mean','AC_mean','AY_mean','AR_mean','A_FTR_A_mean','A_FTR_D_mean','A_FTR_H_mean','A_HTR_A_mean','A_HTR_D_mean','A_HTR_H_mean']]= df_stanford_model.groupby('away_team_name_id')['FTAG','HTAG','AS','AST','AF','AC','AY','AR','FTR_A','FTR_D','FTR_H','HTR_A','HTR_D','HTR_H'].apply(lambda x:x.expanding().mean().shift())\n",
    "\n",
    "    #Selecting features\n",
    "    df_stanford_real_features = df_stanford_model[['id','stage','date','home_team_name_id','away_team_name_id','labels','FTHG_mean','HTHG_mean','HS_mean','HST_mean','HF_mean','HC_mean','HY_mean','HR_mean','H_FTR_A_mean','H_FTR_D_mean','H_FTR_H_mean','H_HTR_A_mean','H_HTR_D_mean','H_HTR_H_mean','FTAG_mean','HTAG_mean','AS_mean','AST_mean','AF_mean','AC_mean','AY_mean','AR_mean','A_FTR_A_mean','A_FTR_D_mean','A_FTR_H_mean','A_HTR_A_mean','A_HTR_D_mean','A_HTR_H_mean']]\n",
    "\n",
    "    #Explanation of name of columns\n",
    "    pd.set_option('display.max_colwidth',120)\n",
    "    exp = pd.DataFrame({'abbreviations':df_stanford_real_features.columns,'Explanation':['id of the match','stage','date','home_team_name_id','away_team_name_id','labels','Mean of Full Time Home Team Goals','Mean of Half Time Home Team Goals','Mean of Home Team Shots','Mean of Home Team Shots on Target','Mean of Home Team Fouls Committed','Mean of Home Team Corners','Mean of Home Team Yellow Cards','Mean of Home Team Red Cards','Mean of games lost at home for the Home Team','Mean of games draw at home for the Home Team','Mean of games won at home for the Home Team ','Mean of games lost at Half Time at home for the Home Team','Mean of games draw at Half Time at home for the Home Team','Mean of games won at Half Time at home for the Home Team','Mean of Full Time Away Team Goals','Mean of Half Time Away Team Goals','Mean of Away Team Shots','Mean of Away Team Shots on Target','Mean of Away Team Fouls Committed','Mean of Away Team Corners','Mean of Away Team Yellow Cards','Mean of Away Team Red Cards','Mean of games won away for the Away Team','Mean of games draw away for the Away Team','Mean of games lost Away for the Away Team ','Mean of games won at Half Time away for the Away Team','Mean of games draw at Half Time away for the Away Team','Mean of games lost at Half Time away for the Away Team']})\n",
    "    #print(exp)\n",
    "    \n",
    "    #Save df in csv\n",
    "    season_footdata = season.replace('/','_').replace('20','') \n",
    "    df_stanford_real_features.to_csv(f'data/df_stanford_real_features_leagues_{league_id}_seasons_{season_footdata}.csv',index=False)\n",
    "\n",
    "    \n",
    "    return df_stanford_real_features\n",
    "\n",
    "\n",
    "datasets = []\n",
    "for league_id in leagues_id:\n",
    "    for season in seasons:\n",
    "        dataset_season = merge_matchtable_footballdata(season,league_id)\n",
    "        datasets.append(dataset_season.loc[:, :])\n",
    "        \n",
    "df_clustering = pd.concat(datasets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Until here we have the origin dataset from which we are going to make the clustering\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 760 entries, 2 to 315\n",
      "Data columns (total 34 columns):\n",
      "id                   760 non-null int64\n",
      "stage                760 non-null int64\n",
      "date                 760 non-null datetime64[ns]\n",
      "home_team_name_id    760 non-null object\n",
      "away_team_name_id    760 non-null object\n",
      "labels               760 non-null object\n",
      "FTHG_mean            720 non-null float64\n",
      "HTHG_mean            720 non-null float64\n",
      "HS_mean              720 non-null float64\n",
      "HST_mean             720 non-null float64\n",
      "HF_mean              720 non-null float64\n",
      "HC_mean              720 non-null float64\n",
      "HY_mean              720 non-null float64\n",
      "HR_mean              720 non-null float64\n",
      "H_FTR_A_mean         720 non-null float64\n",
      "H_FTR_D_mean         720 non-null float64\n",
      "H_FTR_H_mean         720 non-null float64\n",
      "H_HTR_A_mean         720 non-null float64\n",
      "H_HTR_D_mean         720 non-null float64\n",
      "H_HTR_H_mean         720 non-null float64\n",
      "FTAG_mean            720 non-null float64\n",
      "HTAG_mean            720 non-null float64\n",
      "AS_mean              720 non-null float64\n",
      "AST_mean             720 non-null float64\n",
      "AF_mean              720 non-null float64\n",
      "AC_mean              720 non-null float64\n",
      "AY_mean              720 non-null float64\n",
      "AR_mean              720 non-null float64\n",
      "A_FTR_A_mean         720 non-null float64\n",
      "A_FTR_D_mean         720 non-null float64\n",
      "A_FTR_H_mean         720 non-null float64\n",
      "A_HTR_A_mean         720 non-null float64\n",
      "A_HTR_D_mean         720 non-null float64\n",
      "A_HTR_H_mean         720 non-null float64\n",
      "dtypes: datetime64[ns](1), float64(28), int64(2), object(3)\n",
      "memory usage: 207.8+ KB\n"
     ]
    }
   ],
   "source": [
    "df_clustering.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creation of the df where the value between teams is going to be our decision value to make clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>palmas</th>\n",
       "      <th>granada</th>\n",
       "      <th>elche</th>\n",
       "      <th>sociedad</th>\n",
       "      <th>barcelona</th>\n",
       "      <th>getafe</th>\n",
       "      <th>córdoba</th>\n",
       "      <th>málaga</th>\n",
       "      <th>sevilla</th>\n",
       "      <th>eibar</th>\n",
       "      <th>almería</th>\n",
       "      <th>betis</th>\n",
       "      <th>vallecano</th>\n",
       "      <th>valencia</th>\n",
       "      <th>coruña</th>\n",
       "      <th>madrid</th>\n",
       "      <th>celta</th>\n",
       "      <th>atlbilbao</th>\n",
       "      <th>atlmadrid</th>\n",
       "      <th>espanyol</th>\n",
       "      <th>villarreal</th>\n",
       "      <th>gijon</th>\n",
       "      <th>levante</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>palmas</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>granada</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>elche</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sociedad</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>barcelona</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          palmas granada elche sociedad barcelona getafe córdoba málaga  \\\n",
       "palmas       NaN     NaN   NaN      NaN       NaN    NaN     NaN    NaN   \n",
       "granada      NaN     NaN   NaN      NaN       NaN    NaN     NaN    NaN   \n",
       "elche        NaN     NaN   NaN      NaN       NaN    NaN     NaN    NaN   \n",
       "sociedad     NaN     NaN   NaN      NaN       NaN    NaN     NaN    NaN   \n",
       "barcelona    NaN     NaN   NaN      NaN       NaN    NaN     NaN    NaN   \n",
       "\n",
       "          sevilla eibar almería betis vallecano valencia coruña madrid celta  \\\n",
       "palmas        NaN   NaN     NaN   NaN       NaN      NaN    NaN    NaN   NaN   \n",
       "granada       NaN   NaN     NaN   NaN       NaN      NaN    NaN    NaN   NaN   \n",
       "elche         NaN   NaN     NaN   NaN       NaN      NaN    NaN    NaN   NaN   \n",
       "sociedad      NaN   NaN     NaN   NaN       NaN      NaN    NaN    NaN   NaN   \n",
       "barcelona     NaN   NaN     NaN   NaN       NaN      NaN    NaN    NaN   NaN   \n",
       "\n",
       "          atlbilbao atlmadrid espanyol villarreal gijon levante  \n",
       "palmas          NaN       NaN      NaN        NaN   NaN     NaN  \n",
       "granada         NaN       NaN      NaN        NaN   NaN     NaN  \n",
       "elche           NaN       NaN      NaN        NaN   NaN     NaN  \n",
       "sociedad        NaN       NaN      NaN        NaN   NaN     NaN  \n",
       "barcelona       NaN       NaN      NaN        NaN   NaN     NaN  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name_teams = set(df_clustering['home_team_name_id'])\n",
    "\n",
    "df = pd.DataFrame(columns=name_teams, index= name_teams)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n",
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "can only convert an array of size 1 to a Python scalar",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-27f952a52776>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0;31m#Filling our df with the values we want to use for clustering. In this particular case this values come from a previous clustering.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0maway_team\u001b[0m \u001b[0;32min\u001b[0m \u001b[0maway_teams\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m                 \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mteam\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maway_team\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_clust\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf_clust\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'team_away'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m \u001b[0maway_team\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'cluster_labels'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/pandas/core/base.py\u001b[0m in \u001b[0;36mitem\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    729\u001b[0m         \"\"\"\n\u001b[1;32m    730\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 731\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    732\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    733\u001b[0m             \u001b[0;31m# copy numpy's message here because Py26 raises an IndexError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: can only convert an array of size 1 to a Python scalar"
     ]
    }
   ],
   "source": [
    "for i in range(2):\n",
    "    print(i)\n",
    "    if i == 0:    \n",
    "        for team in name_teams:\n",
    "            df_clustering_teams =df_clustering.loc[df_clustering['home_team_name_id']== team,:]\n",
    "\n",
    "\n",
    "            ## Remove Rows With Missing Values\n",
    "            df_clustering_teams.dropna(inplace=True)\n",
    "\n",
    "            #Remove labels and also the columns that we don't want to use as clustering info\n",
    "            away_teams =df_clustering_teams['away_team_name_id']\n",
    "            df_clustering_teams = df_clustering_teams.drop(columns= ['labels','date','id','home_team_name_id','away_team_name_id'])\n",
    "\n",
    "\n",
    "            #Clustering. We use K =5 because we want to distinct between(H+,H,D,A,A+)\n",
    "            kmeans = KMeans(n_clusters=5, random_state=111)\n",
    "            kmeans.fit(df_clustering_teams)\n",
    "\n",
    "\n",
    "            #Plotting clustering in pca2 dimensions\n",
    "            pca = PCA(n_components=2).fit(df_clustering_teams)\n",
    "            pca_2d = pca.transform(df_clustering_teams)\n",
    "\n",
    "        #     fig, ax = plt.subplots(figsize=(15,15))\n",
    "        #     fig.suptitle(f'Home Team: {team}', fontsize=16)\n",
    "        #     ax.scatter(pca_2d[:, 0], pca_2d[:, 1], c=kmeans.labels_, s=1000)\n",
    "        #     for i, txt in enumerate(away_teams):\n",
    "        #         ax.annotate(txt, (pca_2d[i, 0], pca_2d[i, 1]))\n",
    "\n",
    "\n",
    "            df_clust = pd.DataFrame(columns=['team_away','cluster_labels'])\n",
    "            df_clust['team_away']= away_teams\n",
    "            df_clust['cluster_labels']= kmeans.labels_\n",
    "\n",
    "            #Filling our df with the values we want to use for clustering. In this particular case this values come from a previous clustering.\n",
    "            for away_team in away_teams:\n",
    "                df.loc[team,away_team] = df_clust.loc[df_clust['team_away']== away_team,'cluster_labels'].item()\n",
    "\n",
    "\n",
    "\n",
    "        #Fill NaN values due to teams playing to themselves, or due to first match day.\n",
    "        df =df.fillna('unknown')\n",
    "\n",
    "        #We should now transpose the matrix to have as a columns the \"performance calculated\" of the team in the row playing away against the team in the column playing at home.\n",
    "        dfT= df.T\n",
    "\n",
    "        dfT =dfT.astype('category')\n",
    "\n",
    "        print(dfT.info())\n",
    "\n",
    "        dfT = convert_to(dfT,'onehot', all_categorical = True,columns = 'None')\n",
    "\n",
    "        dfT.info()  \n",
    "\n",
    "        #Now we make the clustering for those rows. This clustering wants to cluster teams that have same caracteristics playing away.\n",
    "        name_teams = set(dfT.index)\n",
    "\n",
    "\n",
    "\n",
    "        Sum_of_squared_distances = []\n",
    "        K = range(1,15)\n",
    "        for k in K:\n",
    "            km = KMeans(n_clusters=k)\n",
    "            km = km.fit(dfT)\n",
    "            Sum_of_squared_distances.append(km.inertia_)\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(15,15))    \n",
    "        plt.plot(K, Sum_of_squared_distances, 'bx-')\n",
    "        plt.xlabel('k')\n",
    "        plt.ylabel('Sum_of_squared_distances')\n",
    "        plt.title('Elbow Method For Optimal k')\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "        kmeans = KMeans(n_clusters=6, random_state=111)\n",
    "        kmeans.fit(dfT)\n",
    "\n",
    "        pca = PCA(n_components=2).fit(dfT)\n",
    "        pca_2d = pca.transform(dfT)\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(15,15))\n",
    "        ax.scatter(pca_2d[:, 0], pca_2d[:, 1], c=kmeans.labels_, s=1000)\n",
    "        \n",
    "\n",
    "        for i, txt in enumerate(name_teams):\n",
    "            ax.annotate(txt, (pca_2d[i, 0], pca_2d[i, 1]))\n",
    "    \n",
    "        plt.show()\n",
    "        \n",
    "\n",
    "        df_cluster = pd.DataFrame(columns=['team_away','cluster_team_away','team_home','cluster_team_home'])\n",
    "        df_cluster['team_away']= dfT.index\n",
    "        df_cluster['cluster_team_away']= kmeans.labels_ \n",
    "        print(df_cluster)\n",
    "\n",
    "\n",
    "    elif i ==1:\n",
    "        for team in name_teams:\n",
    "            df_clustering_teams =df_clustering.loc[df_clustering['away_team_name_id']== team,:]\n",
    "\n",
    "\n",
    "            ## Remove Rows With Missing Values\n",
    "            df_clustering_teams.dropna(inplace=True)\n",
    "\n",
    "            #Remove labels and also the columns that we don't want to use as clustering info\n",
    "            away_teams =df_clustering_teams['home_team_name_id']\n",
    "            df_clustering_teams = df_clustering_teams.drop(columns= ['labels','date','id','home_team_name_id','away_team_name_id'])\n",
    "\n",
    "\n",
    "            #Clustering. We use K =5 because we want to distinct between(H+,H,D,A,A+)\n",
    "            kmeans = KMeans(n_clusters=5, random_state=111)\n",
    "            kmeans.fit(df_clustering_teams)\n",
    "\n",
    "\n",
    "            #Plotting clustering in pca2 dimensions\n",
    "            pca = PCA(n_components=2).fit(df_clustering_teams)\n",
    "            pca_2d = pca.transform(df_clustering_teams)\n",
    "\n",
    "        #     fig, ax = plt.subplots(figsize=(15,15))\n",
    "        #     fig.suptitle(f'Home Team: {team}', fontsize=16)\n",
    "        #     ax.scatter(pca_2d[:, 0], pca_2d[:, 1], c=kmeans.labels_, s=1000)\n",
    "        #     for i, txt in enumerate(away_teams):\n",
    "        #         ax.annotate(txt, (pca_2d[i, 0], pca_2d[i, 1]))\n",
    "\n",
    "\n",
    "            df_clust = pd.DataFrame(columns=['team_away','cluster_labels'])\n",
    "            df_clust['team_away']= away_teams\n",
    "            df_clust['cluster_labels']= kmeans.labels_\n",
    "\n",
    "            #Filling our df with the values we want to use for clustering. In this particular case this values come from a previous clustering.\n",
    "            for away_team in away_teams:\n",
    "                df.loc[team,away_team] = df_clust.loc[df_clust['team_away']== away_team,'cluster_labels'].item()\n",
    "\n",
    "\n",
    "\n",
    "        #Fill NaN values due to teams playing to themselves, or due to first match day.\n",
    "        df =df.fillna('unknown')\n",
    "\n",
    "        #We should now transpose the matrix to have as a columns the \"performance calculated\" of the team in the row playing away against the team in the column playing at home.\n",
    "        dfT= df.T\n",
    "\n",
    "        dfT =dfT.astype('category')\n",
    "\n",
    "        print(dfT.info())\n",
    "\n",
    "        dfT = convert_to(dfT,'onehot', all_categorical = True,columns = 'None')\n",
    "\n",
    "        dfT.info()  \n",
    "\n",
    "        #Now we make the clustering for those rows. This clustering wants to cluster teams that have same caracteristics playing away.\n",
    "        name_teams = set(dfT.index)\n",
    "\n",
    "\n",
    "\n",
    "        Sum_of_squared_distances = []\n",
    "        K = range(1,15)\n",
    "        for k in K:\n",
    "            km = KMeans(n_clusters=k)\n",
    "            km = km.fit(dfT)\n",
    "            Sum_of_squared_distances.append(km.inertia_)\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(15,15))    \n",
    "        plt.plot(K, Sum_of_squared_distances, 'bx-')\n",
    "        plt.xlabel('k')\n",
    "        plt.ylabel('Sum_of_squared_distances')\n",
    "        plt.title('Elbow Method For Optimal k')\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "        kmeans = KMeans(n_clusters=6, random_state=111)\n",
    "        kmeans.fit(dfT)\n",
    "\n",
    "        pca = PCA(n_components=2).fit(dfT)\n",
    "        pca_2d = pca.transform(dfT)\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(15,15))\n",
    "        ax.scatter(pca_2d[:, 0], pca_2d[:, 1], c=kmeans.labels_, s=1000)\n",
    "\n",
    "        for i, txt in enumerate(name_teams):\n",
    "            ax.annotate(txt, (pca_2d[i, 0], pca_2d[i, 1]))\n",
    "            \n",
    "            \n",
    "        plt.show()\n",
    "\n",
    "        print(df_cluster)\n",
    "\n",
    "        df_cluster['team_home']= dfT.index\n",
    "        df_cluster['cluster_team_home']= kmeans.labels_   \n",
    "        print(df_cluster)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>team_away</th>\n",
       "      <th>cluster_team_away</th>\n",
       "      <th>team_home</th>\n",
       "      <th>cluster_team_home</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>palmas</td>\n",
       "      <td>2</td>\n",
       "      <td>palmas</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>granada</td>\n",
       "      <td>2</td>\n",
       "      <td>granada</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sociedad</td>\n",
       "      <td>1</td>\n",
       "      <td>sociedad</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>barcelona</td>\n",
       "      <td>0</td>\n",
       "      <td>barcelona</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>getafe</td>\n",
       "      <td>4</td>\n",
       "      <td>getafe</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>málaga</td>\n",
       "      <td>2</td>\n",
       "      <td>málaga</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>sevilla</td>\n",
       "      <td>5</td>\n",
       "      <td>sevilla</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>eibar</td>\n",
       "      <td>3</td>\n",
       "      <td>eibar</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>betis</td>\n",
       "      <td>1</td>\n",
       "      <td>betis</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>vallecano</td>\n",
       "      <td>4</td>\n",
       "      <td>vallecano</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>valencia</td>\n",
       "      <td>4</td>\n",
       "      <td>valencia</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>coruña</td>\n",
       "      <td>1</td>\n",
       "      <td>coruña</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>madrid</td>\n",
       "      <td>0</td>\n",
       "      <td>madrid</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>celta</td>\n",
       "      <td>5</td>\n",
       "      <td>celta</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>atlbilbao</td>\n",
       "      <td>5</td>\n",
       "      <td>atlbilbao</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>atlmadrid</td>\n",
       "      <td>5</td>\n",
       "      <td>atlmadrid</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>espanyol</td>\n",
       "      <td>4</td>\n",
       "      <td>espanyol</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>villarreal</td>\n",
       "      <td>3</td>\n",
       "      <td>villarreal</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>gijon</td>\n",
       "      <td>4</td>\n",
       "      <td>gijon</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>levante</td>\n",
       "      <td>2</td>\n",
       "      <td>levante</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     team_away  cluster_team_away   team_home  cluster_team_home\n",
       "0       palmas                  2      palmas                  2\n",
       "1      granada                  2     granada                  2\n",
       "2     sociedad                  1    sociedad                  1\n",
       "3    barcelona                  0   barcelona                  0\n",
       "4       getafe                  4      getafe                  3\n",
       "5       málaga                  2      málaga                  2\n",
       "6      sevilla                  5     sevilla                  4\n",
       "7        eibar                  3       eibar                  4\n",
       "8        betis                  1       betis                  1\n",
       "9    vallecano                  4   vallecano                  3\n",
       "10    valencia                  4    valencia                  3\n",
       "11      coruña                  1      coruña                  1\n",
       "12      madrid                  0      madrid                  0\n",
       "13       celta                  5       celta                  5\n",
       "14   atlbilbao                  5   atlbilbao                  5\n",
       "15   atlmadrid                  5   atlmadrid                  5\n",
       "16    espanyol                  4    espanyol                  3\n",
       "17  villarreal                  3  villarreal                  1\n",
       "18       gijon                  4       gijon                  3\n",
       "19     levante                  2     levante                  2"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's see if this cluster information alone can give us any useful information\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clustering.head()\n",
    "df_testing_clustering = df_clustering[['labels','home_team_name_id','away_team_name_id','date']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def include_cluster_away(team_away,df_cluster):\n",
    "    clus_away = df_cluster.loc[df_cluster['team_away']==team_away, 'cluster_team_away'].item()\n",
    "    return clus_away"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def include_cluster_home(team_home,df_cluster):\n",
    "    clus_home = df_cluster.loc[df_cluster['team_home']==team_home, 'cluster_team_home'].item()\n",
    "    return clus_home"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "df_testing_clustering['cluster_team_away'] = df_testing_clustering.apply(lambda x: include_cluster_away(x['away_team_name_id'], df_cluster), axis =1 )\n",
    "\n",
    "\n",
    "df_testing_clustering['cluster_team_home'] = df_testing_clustering.apply(lambda x: include_cluster_home(x['home_team_name_id'], df_cluster), axis =1 )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "      <th>home_team_name_id</th>\n",
       "      <th>away_team_name_id</th>\n",
       "      <th>date</th>\n",
       "      <th>cluster_team_away</th>\n",
       "      <th>cluster_team_home</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>D</td>\n",
       "      <td>málaga</td>\n",
       "      <td>sevilla</td>\n",
       "      <td>2015-08-21</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>H</td>\n",
       "      <td>atlmadrid</td>\n",
       "      <td>palmas</td>\n",
       "      <td>2015-08-22</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>H</td>\n",
       "      <td>espanyol</td>\n",
       "      <td>getafe</td>\n",
       "      <td>2015-08-22</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>D</td>\n",
       "      <td>coruña</td>\n",
       "      <td>sociedad</td>\n",
       "      <td>2015-08-22</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>D</td>\n",
       "      <td>vallecano</td>\n",
       "      <td>valencia</td>\n",
       "      <td>2015-08-22</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  labels home_team_name_id away_team_name_id       date  cluster_team_away  \\\n",
       "2      D            málaga           sevilla 2015-08-21                  5   \n",
       "1      H         atlmadrid            palmas 2015-08-22                  2   \n",
       "5      H          espanyol            getafe 2015-08-22                  4   \n",
       "8      D            coruña          sociedad 2015-08-22                  1   \n",
       "9      D         vallecano          valencia 2015-08-22                  4   \n",
       "\n",
       "   cluster_team_home  \n",
       "2                  2  \n",
       "1                  5  \n",
       "5                  3  \n",
       "8                  1  \n",
       "9                  3  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_testing_clustering.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "seasons_data = []\n",
    "for season in seasons:\n",
    "    seasons_data.append(season.replace('/','_').replace('20',''))\n",
    "\n",
    "location_to_file = 'data/'\n",
    "df_testing_clustering.to_csv(location_to_file+f'df_testing_clustering_app2_{leagues_id}_seasons_{seasons_data}.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for *: 'float' and 'Timestamp'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-5c689091045f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mncenters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxes1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     cntr, u, u0, d, jm, p, fpc = fuzz.cluster.cmeans(\n\u001b[0;32m---> 17\u001b[0;31m         df_clustering, ncenters, 2, error=0.005, maxiter=1000, init=None)\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;31m# Store fpc values for later\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/skfuzzy/cluster/_cmeans.py\u001b[0m in \u001b[0;36mcmeans\u001b[0;34m(data, c, m, error, maxiter, metric, init, seed)\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0mp\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mmaxiter\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m         \u001b[0mu2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m         \u001b[0;34m[\u001b[0m\u001b[0mcntr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mJjm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_cmeans0\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mu2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m         \u001b[0mjm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mJjm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m         \u001b[0mp\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/skfuzzy/cluster/_cmeans.py\u001b[0m in \u001b[0;36m_cmeans0\u001b[0;34m(data, u_old, c, m, metric)\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;31m# Calculate cluster centers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0mcntr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mum\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0matleast_2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mum\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_distance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcntr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for *: 'float' and 'Timestamp'"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlsAAAJDCAYAAAA8QNGHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4wLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvqOYd8AAAIABJREFUeJzt3WGIZXd9//H3x2xTaRq1mBEku2si/03jVgumQ2oRaopp2aSw+8BWdkFaS3DRGikohRRLGuIjW2pB2NYuVKKCxtUHZcCVlNpIQNyYCdHoboiMq202ShM1+iTEGPr9P7g35p5x587Z3fObeyb7fsHAPff+9v6+3J0PfObMmXtTVUiSJKmNlyx6AEmSpBczy5YkSVJDli1JkqSGLFuSJEkNWbYkSZIasmxJkiQ1tGnZSvLxJE8k+dYGjyfJR5OsJXk4yXXDjymNh5mQusyENF+fM1t3AfvmPH4TsGf6dRj4lwsfSxq1uzAT0qy7MBPShjYtW1V1H/DjOUsOAJ+siRPAK5K8eqgBpbExE1KXmZDmG+KarSuBx2aOz0zvky5WZkLqMhO6qO3Yys2SHGZyCpnLLrvsd6699tqt3F7a0IMPPvjDqlra6n3NhMbKTEhdF5KJIcrW48CumeOd0/t+SVUdBY4CLC8v1+rq6gDbSxcuyX8P+HRmQtuemZC6LiQTQ/wacQX4s+lfm7wJ+GlV/WCA55W2KzMhdZkJXdQ2PbOV5DPADcAVSc4Afwf8CkBVfQw4DtwMrAFPA3/RalhpDMyE1GUmpPk2LVtVdWiTxwt472ATSSNnJqQuMyHN5zvIS5IkNWTZkiRJasiyJUmS1JBlS5IkqSHLliRJUkOWLUmSpIYsW5IkSQ1ZtiRJkhqybEmSJDVk2ZIkSWrIsiVJktSQZUuSJKkhy5YkSVJDli1JkqSGLFuSJEkNWbYkSZIasmxJkiQ1ZNmSJElqyLIlSZLUkGVLkiSpIcuWJElSQ5YtSZKkhixbkiRJDfUqW0n2JXk0yVqS287y+O4k9yZ5KMnDSW4eflRpPMyE1GUmpI1tWraSXAIcAW4C9gKHkuxdt+xvgWNV9UbgIPDPQw8qjYWZkLrMhDRfnzNb1wNrVXW6qp4F7gYOrFtTwMumt18OfH+4EaXRMRNSl5mQ5tjRY82VwGMzx2eA31235g7gP5K8D7gMuHGQ6aRxMhNSl5mQ5hjqAvlDwF1VtRO4GfhUkl967iSHk6wmWX3yyScH2loaJTMhdZkJXbT6lK3HgV0zxzun9826BTgGUFVfBV4KXLH+iarqaFUtV9Xy0tLS+U0sLZ6ZkLrMhDRHn7L1ALAnydVJLmVyYePKujX/A7wVIMnrmITIH0n0YmUmpC4zIc2xadmqqueAW4F7gEeY/DXJySR3Jtk/XfYB4F1JvgF8BnhnVVWroaVFMhNSl5mQ5utzgTxVdRw4vu6+22dunwLePOxo0niZCanLTEgb8x3kJUmSGrJsSZIkNWTZkiRJasiyJUmS1JBlS5IkqSHLliRJUkOWLUmSpIYsW5IkSQ1ZtiRJkhqybEmSJDVk2ZIkSWrIsiVJktSQZUuSJKkhy5YkSVJDli1JkqSGLFuSJEkNWbYkSZIasmxJkiQ1ZNmSJElqyLIlSZLUkGVLkiSpIcuWJElSQ5YtSZKkhnqVrST7kjyaZC3JbRuseXuSU0lOJvn0sGNK42ImpC4zIW1sx2YLklwCHAH+EDgDPJBkpapOzazZA/wN8OaqeirJq1oNLC2amZC6zIQ0X58zW9cDa1V1uqqeBe4GDqxb8y7gSFU9BVBVTww7pjQqZkLqMhPSHH3K1pXAYzPHZ6b3zboGuCbJV5KcSLJvqAGlETITUpeZkObY9NeI5/A8e4AbgJ3AfUneUFU/mV2U5DBwGGD37t0DbS2NkpmQusyELlp9zmw9DuyaOd45vW/WGWClqn5eVd8Fvs0kVB1VdbSqlqtqeWlp6XxnlhbNTEhdZkKao0/ZegDYk+TqJJcCB4GVdWv+nclPKyS5gsnp4tMDzimNiZmQusyENMemZauqngNuBe4BHgGOVdXJJHcm2T9ddg/woySngHuBv66qH7UaWlokMyF1mQlpvlTVQjZeXl6u1dXVhewtrZfkwapaXuQMZkJjYiakrgvJhO8gL0mS1JBlS5IkqSHLliRJUkOWLUmSpIYsW5IkSQ1ZtiRJkhqybEmSJDVk2ZIkSWrIsiVJktSQZUuSJKkhy5YkSVJDli1JkqSGLFuSJEkNWbYkSZIasmxJkiQ1ZNmSJElqyLIlSZLUkGVLkiSpIcuWJElSQ5YtSZKkhixbkiRJDVm2JEmSGrJsSZIkNdSrbCXZl+TRJGtJbpuz7m1JKsnycCNK42MmpC4zIW1s07KV5BLgCHATsBc4lGTvWdZdDvwVcP/QQ0pjYiakLjMhzdfnzNb1wFpVna6qZ4G7gQNnWfch4MPAMwPOJ42RmZC6zIQ0R5+ydSXw2Mzxmel9v5DkOmBXVX1hwNmksTITUpeZkOa44Avkk7wE+AjwgR5rDydZTbL65JNPXujW0iiZCanLTOhi16dsPQ7smjneOb3veZcDrwe+nOR7wJuAlbNd/FhVR6tquaqWl5aWzn9qabHMhNRlJqQ5+pStB4A9Sa5OcilwEFh5/sGq+mlVXVFVV1XVVcAJYH9VrTaZWFo8MyF1mQlpjk3LVlU9B9wK3AM8AhyrqpNJ7kyyv/WA0tiYCanLTEjz7eizqKqOA8fX3Xf7BmtvuPCxpHEzE1KXmZA25jvIS5IkNWTZkiRJasiyJUmS1JBlS5IkqSHLliRJUkOWLUmSpIYsW5IkSQ1ZtiRJkhqybEmSJDVk2ZIkSWrIsiVJktSQZUuSJKkhy5YkSVJDli1JkqSGLFuSJEkNWbYkSZIasmxJkiQ1ZNmSJElqyLIlSZLUkGVLkiSpIcuWJElSQ5YtSZKkhixbkiRJDfUqW0n2JXk0yVqS287y+PuTnErycJIvJXnN8KNK42EmpC4zIW1s07KV5BLgCHATsBc4lGTvumUPActV9dvA54G/H3pQaSzMhNRlJqT5+pzZuh5Yq6rTVfUscDdwYHZBVd1bVU9PD08AO4cdUxoVMyF1mQlpjj5l60rgsZnjM9P7NnIL8MULGUoaOTMhdZkJaY4dQz5ZkncAy8BbNnj8MHAYYPfu3UNuLY2SmZC6zIQuRn3ObD0O7Jo53jm9ryPJjcAHgf1V9bOzPVFVHa2q5apaXlpaOp95pTEwE1KXmZDm6FO2HgD2JLk6yaXAQWBldkGSNwL/yiRATww/pjQqZkLqMhPSHJuWrap6DrgVuAd4BDhWVSeT3Jlk/3TZPwC/DnwuydeTrGzwdNK2ZyakLjMhzdfrmq2qOg4cX3ff7TO3bxx4LmnUzITUZSakjfkO8pIkSQ1ZtiRJkhqybEmSJDVk2ZIkSWrIsiVJktSQZUuSJKkhy5YkSVJDli1JkqSGLFuSJEkNWbYkSZIasmxJkiQ1ZNmSJElqyLIlSZLUkGVLkiSpIcuWJElSQ5YtSZKkhixbkiRJDVm2JEmSGrJsSZIkNWTZkiRJasiyJUmS1JBlS5IkqSHLliRJUkO9ylaSfUkeTbKW5LazPP6rST47ffz+JFcNPag0JmZC6jIT0sY2LVtJLgGOADcBe4FDSfauW3YL8FRV/T/gn4APDz2oNBZmQuoyE9J8fc5sXQ+sVdXpqnoWuBs4sG7NAeAT09ufB96aJMONKY2KmZC6zIQ0R5+ydSXw2Mzxmel9Z11TVc8BPwVeOcSA0giZCanLTEhz7NjKzZIcBg5PD3+W5Ftbuf9ZXAH80BkWPsOi9wf4zUVsaiZGOcOi9x/LDGZiYgz/F4ueYdH7j2WG885En7L1OLBr5njn9L6zrTmTZAfwcuBH65+oqo4CRwGSrFbV8vkMPRRnGMcMi97/+RnOYbmZeBHPsOj9xzTDOSw3Ey/iGRa9/5hmON9/2+fXiA8Ae5JcneRS4CCwsm7NCvDn09t/AvxXVdX5DiWNnJmQusyENMemZ7aq6rkktwL3AJcAH6+qk0nuBFaragX4N+BTSdaAHzMJmvSiZCakLjMhzdfrmq2qOg4cX3ff7TO3nwH+9Bz3PnqO61twholFz7Do/eEcZzATTS16hkXvD9twBjPR1KJnWPT+sM1niGdxJUmS2vHjeiRJkhpqXrbG8BEOPWZ4f5JTSR5O8qUkr9nK/WfWvS1JJRn8Ly76zJDk7dPX4WSST2/1DEl2J7k3yUPT/4ubB97/40me2OhPyTPx0el8Dye5bsj9Z/YxE2ai1wxm4hePN83EovPQZ4aZdWZiO2aiqpp9MblQ8jvAa4FLgW8Ae9et+UvgY9PbB4HPLmCGPwB+bXr7PUPO0Gf/6brLgfuAE8DyAl6DPcBDwG9Mj1+1gBmOAu+Z3t4LfG/gGX4fuA741gaP3wx8EQjwJuD+Ifc/h9fBTJSZmK4xE9U2E4vOQ98ZpuvMxDbNROszW2P4CIdNZ6iqe6vq6enhCSbvEbNl+099iMlnhT0z4N7nMsO7gCNV9RRAVT2xgBkKeNn09suB7w85QFXdx+SvoDZyAPhkTZwAXpHk1UPOgJnotf+UmTATs3O0ysSi89BrhikzsU0z0bpsjeEjHPrMMOsWJq11y/afnobcVVVfGHDfc5oBuAa4JslXkpxIsm8BM9wBvCPJGSZ/1fS+gWfYzLl+r7Taw0yYiefdgZnorGmQiUXnodcMZuIX7mAbZmJLP65n7JK8A1gG3rKFe74E+Ajwzq3acwM7mJwivoHJT233JXlDVf1kC2c4BNxVVf+Y5PeYvCfP66vq/7ZwBs0wE2ZCL1hEHqb7mokXbMtMtD6zdS4f4UDmfIRD4xlIciPwQWB/Vf1sC/e/HHg98OUk32PyO+CVgS9+7PManAFWqurnVfVd4NtMQrWVM9wCHAOoqq8CL2XyeVhbpdf3yhbsYSbMxPPMxLo1DTKx6Dz0mcFMvGB7ZmLIC8vOciHZDuA0cDUvXOz2W+vWvJfuhY/HFjDDG5lclLdnEa/BuvVfZvgLH/u8BvuAT0xvX8HkNOkrt3iGLwLvnN5+HZPfxWfg1+IqNr7w8Y/pXvj4tUV8P5gJMzGzxkxU20wsOg99Z1i33kzU9srE4N80ZxnsZibt9zvAB6f33cnkpwOYtNLPAWvA14DXLmCG/wT+F/j69GtlK/dft3bwEPV8DcLkNPUp4JvAwQXMsBf4yjRgXwf+aOD9PwP8APg5k5/QbgHeDbx75jU4Mp3vmy3+H3q+Dmaiu9ZMmImmmVh0HvrMsG6tmdhmmfAd5CVJkhryHeQlSZIasmxJkiQ1ZNmSJElqyLIlSZLUkGVLkiSpIcuWJElSQ5YtSZKkhixbkiRJDVm2JEmSGrJsSZIkNWTZkiRJasiyJUmS1NCmZSvJx5M8keRbGzyeJB9Nspbk4STXDT+mNB5mQuoyE9J8fc5s3QXsm/P4TcCe6ddh4F8ufCxp1O7CTEiz7sJMSBvatGxV1X3Aj+csOQB8siZOAK9I8uqhBpTGxkxIXWZCmm+Ia7auBB6bOT4zvU+6WJkJqctM6KK2Yys3S3KYySlkLrvsst+59tprt3J7aUMPPvjgD6tqaav3NRMaKzMhdV1IJoYoW48Du2aOd07v+yVVdRQ4CrC8vFyrq6sDbC9duCT/PeDTmQlte2ZC6rqQTAzxa8QV4M+mf23yJuCnVfWDAZ5X2q7MhNRlJnRR2/TMVpLPADcAVyQ5A/wd8CsAVfUx4DhwM7AGPA38RathpTEwE1KXmZDm27RsVdWhTR4v4L2DTSSNnJmQusyENJ/vIC9JktSQZUuSJKkhy5YkSVJDli1JkqSGLFuSJEkNWbYkSZIasmxJkiQ1ZNmSJElqyLIlSZLUkGVLkiSpIcuWJElSQ5YtSZKkhixbkiRJDVm2JEmSGrJsSZIkNWTZkiRJasiyJUmS1JBlS5IkqSHLliRJUkOWLUmSpIYsW5IkSQ1ZtiRJkhqybEmSJDXUq2wl2Zfk0SRrSW47y+O7k9yb5KEkDye5efhRpfEwE1KXmZA2tmnZSnIJcAS4CdgLHEqyd92yvwWOVdUbgYPAPw89qDQWZkLqMhPSfH3ObF0PrFXV6ap6FrgbOLBuTQEvm95+OfD94UaURsdMSF1mQppjR481VwKPzRyfAX533Zo7gP9I8j7gMuDGQaaTxslMSF1mQppjqAvkDwF3VdVO4GbgU0l+6bmTHE6ymmT1ySefHGhraZTMhNRlJnTR6lO2Hgd2zRzvnN436xbgGEBVfRV4KXDF+ieqqqNVtVxVy0tLS+c3sbR4ZkLqMhPSHH3K1gPAniRXJ7mUyYWNK+vW/A/wVoAkr2MSIn8k0YuVmZC6zIQ0x6Zlq6qeA24F7gEeYfLXJCeT3Jlk/3TZB4B3JfkG8BngnVVVrYaWFslMSF1mQpqvzwXyVNVx4Pi6+26fuX0KePOwo0njZSakLjMhbcx3kJckSWrIsiVJktSQZUuSJKkhy5YkSVJDli1JkqSGLFuSJEkNWbYkSZIasmxJkiQ1ZNmSJElqyLIlSZLUkGVLkiSpIcuWJElSQ5YtSZKkhixbkiRJDVm2JEmSGrJsSZIkNWTZkiRJasiyJUmS1JBlS5IkqSHLliRJUkOWLUmSpIYsW5IkSQ1ZtiRJkhrqVbaS7EvyaJK1JLdtsObtSU4lOZnk08OOKY2LmZC6zIS0sR2bLUhyCXAE+EPgDPBAkpWqOjWzZg/wN8Cbq+qpJK9qNbC0aGZC6jIT0nx9zmxdD6xV1emqeha4Gziwbs27gCNV9RRAVT0x7JjSqJgJqctMSHP0KVtXAo/NHJ+Z3jfrGuCaJF9JciLJvqEGlEbITEhdZkKaY9NfI57D8+wBbgB2AvcleUNV/WR2UZLDwGGA3bt3D7S1NEpmQuoyE7po9Tmz9Tiwa+Z45/S+WWeAlar6eVV9F/g2k1B1VNXRqlququWlpaXznVlaNDMhdZkJaY4+ZesBYE+Sq5NcChwEVtat+XcmP62Q5Aomp4tPDzinNCZmQuoyE9Icm5atqnoOuBW4B3gEOFZVJ5PcmWT/dNk9wI+SnALuBf66qn7UamhpkcyE1GUmpPlSVQvZeHl5uVZXVxeyt7RekgeranmRM5gJjYmZkLouJBO+g7wkSVJDli1JkqSGLFuSJEkNWbYkSZIasmxJkiQ1ZNmSJElqyLIlSZLUkGVLkiSpIcuWJElSQ5YtSZKkhixbkiRJDVm2JEmSGrJsSZIkNWTZkiRJasiyJUmS1JBlS5IkqSHLliRJUkOWLUmSpIYsW5IkSQ1ZtiRJkhqybEmSJDVk2ZIkSWrIsiVJktRQr7KVZF+SR5OsJbltzrq3Jakky8ONKI2PmZC6zIS0sU3LVpJLgCPATcBe4FCSvWdZdznwV8D9Qw8pjYmZkLrMhDRfnzNb1wNrVXW6qp4F7gYOnGXdh4APA88MOJ80RmZC6jIT0hx9ytaVwGMzx2em9/1CkuuAXVX1hQFnk8bKTEhdZkKa44IvkE/yEuAjwAd6rD2cZDXJ6pNPPnmhW0ujZCakLjOhi12fsvU4sGvmeOf0vuddDrwe+HKS7wFvAlbOdvFjVR2tquWqWl5aWjr/qaXFMhNSl5mQ5uhTth4A9iS5OsmlwEFg5fkHq+qnVXVFVV1VVVcBJ4D9VbXaZGJp8cyE1GUmpDk2LVtV9RxwK3AP8AhwrKpOJrkzyf7WA0pjYyakLjMhzbejz6KqOg4cX3ff7RusveHCx5LGzUxIXWZC2pjvIC9JktSQZUuSJKkhy5YkSVJDli1JkqSGLFuSJEkNWbYkSZIasmxJkiQ1ZNmSJElqyLIlSZLUkGVLkiSpIcuWJElSQ5YtSZKkhixbkiRJDVm2JEmSGrJsSZIkNWTZkiRJasiyJUmS1JBlS5IkqSHLliRJUkOWLUmSpIYsW5IkSQ1ZtiRJkhqybEmSJDXUq2wl2Zfk0SRrSW47y+PvT3IqycNJvpTkNcOPKo2HmZC6zIS0sU3LVpJLgCPATcBe4FCSveuWPQQsV9VvA58H/n7oQaWxMBNSl5mQ5utzZut6YK2qTlfVs8DdwIHZBVV1b1U9PT08AewcdkxpVMyE1GUmpDn6lK0rgcdmjs9M79vILcAXL2QoaeTMhNRlJqQ5dgz5ZEneASwDb9ng8cPAYYDdu3cPubU0SmZC6jITuhj1ObP1OLBr5njn9L6OJDcCHwT2V9XPzvZEVXW0qparanlpael85pXGwExIXWZCmqNP2XoA2JPk6iSXAgeBldkFSd4I/CuTAD0x/JjSqJgJqctMSHNsWraq6jngVuAe4BHgWFWdTHJnkv3TZf8A/DrwuSRfT7KywdNJ256ZkLrMhDRfr2u2quo4cHzdfbfP3L5x4LmkUTMTUpeZkDbmO8hLkiQ1ZNmSJElqyLIlSZLUkGVLkiSpIcuWJElSQ5YtSZKkhixbkiRJDVm2JEmSGrJsSZIkNWTZkiRJasiyJUmS1JBlS5IkqSHLliRJUkOWLUmSpIYsW5IkSQ1ZtiRJkhqybEmSJDVk2ZIkSWrIsiVJktSQZUuSJKkhy5YkSVJDli1JkqSGLFuSJEkN9SpbSfYleTTJWpLbzvL4ryb57PTx+5NcNfSg0piYCanLTEgb27RsJbkEOALcBOwFDiXZu27ZLcBTVfX/gH8CPjz0oNJYmAmpy0xI8/U5s3U9sFZVp6vqWeBu4MC6NQeAT0xvfx54a5IMN6Y0KmZC6jIT0hx9ytaVwGMzx2em9511TVU9B/wUeOUQA0ojZCakLjMhzbFjKzdLchg4PD38WZJvbeX+Z3EF8ENnWPgMi94f4DcXsamZGOUMi95/LDOYiYkx/F8seoZF7z+WGc47E33K1uPArpnjndP7zrbmTJIdwMuBH61/oqo6ChwFSLJaVcvnM/RQnGEcMyx6/+dnOIflZuJFPMOi9x/TDOew3Ey8iGdY9P5jmuF8/22fXyM+AOxJcnWSS4GDwMq6NSvAn09v/wnwX1VV5zuUNHJmQuoyE9Icm57ZqqrnktwK3ANcAny8qk4muRNYraoV4N+ATyVZA37MJGjSi5KZkLrMhDRfr2u2quo4cHzdfbfP3H4G+NNz3PvoOa5vwRkmFj3DoveHc5zBTDS16BkWvT9swxnMRFOLnmHR+8M2nyGexZUkSWrHj+uRJElqqHnZGsNHOPSY4f1JTiV5OMmXkrxmK/efWfe2JJVk8L+46DNDkrdPX4eTST691TMk2Z3k3iQPTf8vbh54/48neWKjPyXPxEen8z2c5Loh95/Zx0yYiV4zmIlfPN40E4vOQ58ZZtaZie2Yiapq9sXkQsnvAK8FLgW+Aexdt+YvgY9Nbx8EPruAGf4A+LXp7fcMOUOf/afrLgfuA04Aywt4DfYADwG/MT1+1QJmOAq8Z3p7L/C9gWf4feA64FsbPH4z8EUgwJuA+4fc/xxeBzNRZmK6xkxU20wsOg99Z5iuMxPbNBOtz2yN4SMcNp2hqu6tqqenhyeYvEfMlu0/9SEmnxX2zIB7n8sM7wKOVNVTAFX1xAJmKOBl09svB74/5ABVdR+Tv4LayAHgkzVxAnhFklcPOQNmotf+U2bCTMzO0SoTi85DrxmmzMQ2zUTrsjWGj3DoM8OsW5i01i3bf3oacldVfWHAfc9pBuAa4JokX0lyIsm+BcxwB/COJGeY/FXT+waeYTPn+r3Sag8zYSaedwdmorOmQSYWnYdeM5iJX7iDbZiJLf24nrFL8g5gGXjLFu75EuAjwDu3as8N7GByivgGJj+13ZfkDVX1ky2c4RBwV1X9Y5LfY/KePK+vqv/bwhk0w0yYCb1gEXmY7msmXrAtM9H6zNa5fIQDmfMRDo1nIMmNwAeB/VX1sy3c/3Lg9cCXk3yPye+AVwa++LHPa3AGWKmqn1fVd4FvMwnVVs5wC3AMoKq+CryUyedhbZVe3ytbsIeZMBPPMxPr1jTIxKLz0GcGM/GC7ZmJIS8sO8uFZDuA08DVvHCx22+tW/Neuhc+HlvADG9kclHenkW8BuvWf5nhL3zs8xrsAz4xvX0Fk9Okr9ziGb4IvHN6+3VMfhefgV+Lq9j4wsc/pnvh49cW8f1gJszEzBozUW0zseg89J1h3XozUdsrE4N/05xlsJuZtN/vAB+c3ncnk58OYNJKPwesAV8DXruAGf4T+F/g69Ovla3cf93awUPU8zUIk9PUp4BvAgcXMMNe4CvTgH0d+KOB9/8M8APg50x+QrsFeDfw7pnX4Mh0vm+2+H/o+TqYie5aM2EmmmZi0XnoM8O6tWZim2XCd5CXJElqyHeQlyRJasiyJUmS1JBlS5IkqSHLliRJUkOWLUmSpIYsW5IkSQ1ZtiRJkhqybEmSJDVk2ZIkSWrIsiVJktSQZUuSJKkhy5YkSVJDm5atJB9P8kSSb23weJJ8NMlakoeTXDf8mNJ4mAmpy0xI8/U5s3UXsG/O4zcBe6Zfh4F/ufCxpFG7CzMhzboLMyFtaNOyVVX3AT+es+QA8MmaOAG8IsmrhxpQGhszIXWZCWm+Ia7ZuhJ4bOb4zPQ+6WJlJqQuM6GL2o6t3CzJYSankLnssst+59prr93K7aUNPfjggz+sqqWt3tdMaKzMhNR1IZkYomw9DuyaOd45ve+XVNVR4CjA8vJyra6uDrC9dOGS/PeAT2cmtO2ZCanrQjIxxK8RV4A/m/61yZuAn1bVDwZ4Xmm7MhNSl5nQRW3TM1tJPgPcAFyR5Azwd8CvAFTVx4DjwM3AGvA08BethpXGwExIXWZCmm/TslVVhzZ5vID3DjaRNHJmQuoyE9J8voO8JElSQ5YtSZKkhixbkiRJDVm2JEmSGrJsSZIkNWTZkiRJasiyJUmS1JBlS5IkqSHLliRJUkOWLUmSpIYsW5IkSQ1ZtiRJkhqybEmSJDVk2ZIkSWrIsiVJktSQZUuSJKkhy5YkSVJDli1JkqSGLFuSJEkNWbYkSZIasmxJkiQ1ZNmSJElqyLIlSZLUUK+ylWRfkkeTrCW57SyP705yb5KHkjyc5ObhR5XGw0xIXWZC2timZSvJJcAR4CZgL3Aoyd51y/4WOFZVbwQOAv889KDSWJgJqctMSPP1ObN1PbDxgi8ZAAAMgElEQVRWVaer6lngbuDAujUFvGx6++XA94cbURodMyF1mQlpjh091lwJPDZzfAb43XVr7gD+I8n7gMuAGweZThonMyF1mQlpjqEukD8E3FVVO4GbgU8l+aXnTnI4yWqS1SeffHKgraVRMhNSl5nQRatP2Xoc2DVzvHN636xbgGMAVfVV4KXAFeufqKqOVtVyVS0vLS2d38TS4pkJqctMSHP0KVsPAHuSXJ3kUiYXNq6sW/M/wFsBkryOSYj8kUQvVmZC6jIT0hyblq2qeg64FbgHeITJX5OcTHJnkv3TZR8A3pXkG8BngHdWVbUaWlokMyF1mQlpvj4XyFNVx4Hj6+67feb2KeDNw44mjZeZkLrMhLQx30FekiSpIcuWJElSQ5YtSZKkhixbkiRJDVm2JEmSGrJsSZIkNWTZkiRJasiyJUmS1JBlS5IkqSHLliRJUkOWLUmSpIYsW5IkSQ1ZtiRJkhqybEmSJDVk2ZIkSWrIsiVJktSQZUuSJKkhy5YkSVJDli1JkqSGLFuSJEkNWbYkSZIasmxJkiQ1ZNmSJElqqFfZSrIvyaNJ1pLctsGatyc5leRkkk8PO6Y0LmZC6jIT0sZ2bLYgySXAEeAPgTPAA0lWqurUzJo9wN8Ab66qp5K8qtXA0qKZCanLTEjz9TmzdT2wVlWnq+pZ4G7gwLo17wKOVNVTAFX1xLBjSqNiJqQuMyHN0adsXQk8NnN8ZnrfrGuAa5J8JcmJJPuGGlAaITMhdZkJaY5Nf414Ds+zB7gB2Ancl+QNVfWT2UVJDgOHAXbv3j3Q1tIomQmpy0zootXnzNbjwK6Z453T+2adAVaq6udV9V3g20xC1VFVR6tquaqWl5aWzndmadHMhNRlJqQ5+pStB4A9Sa5OcilwEFhZt+bfmfy0QpIrmJwuPj3gnNKYmAmpy0xIc2xatqrqOeBW4B7gEeBYVZ1McmeS/dNl9wA/SnIKuBf466r6UauhpUUyE1KXmZDmS1UtZOPl5eVaXV1dyN7SekkerKrlRc5gJjQmZkLqupBM+A7ykiRJDVm2JEmSGrJsSZIkNWTZkiRJasiyJUmS1JBlS5IkqSHLliRJUkOWLUmSpIYsW5IkSQ1ZtiRJkhqybEmSJDVk2ZIkSWrIsiVJktSQZUuSJKkhy5YkSVJDli1JkqSGLFuSJEkNWbYkSZIasmxJkiQ1ZNmSJElqyLIlSZLUkGVLkiSpIcuWJElSQ73KVpJ9SR5Nspbktjnr3pakkiwPN6I0PmZC6jIT0sY2LVtJLgGOADcBe4FDSfaeZd3lwF8B9w89pDQmZkLqMhPSfH3ObF0PrFXV6ap6FrgbOHCWdR8CPgw8M+B80hiZCanLTEhz9ClbVwKPzRyfmd73C0muA3ZV1RcGnE0aKzMhdZkJaY4LvkA+yUuAjwAf6LH2cJLVJKtPPvnkhW4tjZKZkLrMhC52fcrW48CumeOd0/uedznweuDLSb4HvAlYOdvFj1V1tKqWq2p5aWnp/KeWFstMSF1mQpqjT9l6ANiT5OoklwIHgZXnH6yqn1bVFVV1VVVdBZwA9lfVapOJpcUzE1KXmZDm2LRsVdVzwK3APcAjwLGqOpnkziT7Ww8ojY2ZkLrMhDTfjj6Lquo4cHzdfbdvsPaGCx9LGjczIXWZCWljvoO8JElSQ5YtSZKkhixbkiRJDVm2JEmSGrJsSZIkNWTZkiRJasiyJUmS1JBlS5IkqSHLliRJUkOWLUmSpIYsW5IkSQ1ZtiRJkhqybEmSJDVk2ZIkSWrIsiVJktSQZUuSJKkhy5YkSVJDli1JkqSGLFuSJEkNWbYkSZIasmxJkiQ1ZNmSJElqyLIlSZLUUK+ylWRfkkeTrCW57SyPvz/JqSQPJ/lSktcMP6o0HmZC6jIT0sY2LVtJLgGOADcBe4FDSfauW/YQsFxVvw18Hvj7oQeVxsJMSF1mQpqvz5mt64G1qjpdVc8CdwMHZhdU1b1V9fT08ASwc9gxpVExE1KXmZDm6FO2rgQemzk+M71vI7cAX7yQoaSRMxNSl5mQ5tgx5JMleQewDLxlg8cPA4cBdu/ePeTW0iiZCanLTOhi1OfM1uPArpnjndP7OpLcCHwQ2F9VPzvbE1XV0aparqrlpaWl85lXGgMzIXWZCWmOPmXrAWBPkquTXAocBFZmFyR5I/CvTAL0xPBjSqNiJqQuMyHNsWnZqqrngFuBe4BHgGNVdTLJnUn2T5f9A/DrwOeSfD3JygZPJ217ZkLqMhPSfL2u2aqq48DxdffdPnP7xoHnkkbNTEhdZkLamO8gL0mS1JBlS5IkqSHLliRJUkOWLUmSpIYsW5IkSQ1ZtiRJkhqybEmSJDVk2ZIkSWrIsiVJktSQZUuSJKkhy5YkSVJDli1JkqSGLFuSJEkNWbYkSZIasmxJkiQ1ZNmSJElqyLIlSZLUkGVLkiSpIcuWJElSQ5YtSZKkhixbkiRJDVm2JEmSGrJsSZIkNdSrbCXZl+TRJGtJbjvL47+a5LPTx+9PctXQg0pjYiakLjMhbWzTspXkEuAIcBOwFziUZO+6ZbcAT1XV/wP+Cfjw0INKY2EmpC4zIc3X58zW9cBaVZ2uqmeBu4ED69YcAD4xvf154K1JMtyY0qiYCanLTEhz9ClbVwKPzRyfmd531jVV9RzwU+CVQwwojZCZkLrMhDTHjq3cLMlh4PD08GdJvrWV+5/FFcAPnWHhMyx6f4DfXMSmZmKUMyx6/7HMYCYmxvB/segZFr3/WGY470z0KVuPA7tmjndO7zvbmjNJdgAvB360/omq6ihwFCDJalUtn8/QQ3GGccyw6P2fn+EclpuJF/EMi95/TDOcw3Iz8SKeYdH7j2mG8/23fX6N+ACwJ8nVSS4FDgIr69asAH8+vf0nwH9VVZ3vUNLImQmpy0xIc2x6ZquqnktyK3APcAnw8ao6meROYLWqVoB/Az6VZA34MZOgSS9KZkLqMhPSfL2u2aqq48DxdffdPnP7GeBPz3Hvo+e4vgVnmFj0DIveH85xBjPR1KJnWPT+sA1nMBNNLXqGRe8P23yGeBZXkiSpHT+uR5IkqaHmZWsMH+HQY4b3JzmV5OEkX0rymq3cf2bd25JUksH/4qLPDEnePn0dTib59FbPkGR3knuTPDT9v7h54P0/nuSJjf6UPBMfnc73cJLrhtx/Zh8zYSZ6zWAmfvF400wsOg99ZphZZya2YyaqqtkXkwslvwO8FrgU+Aawd92avwQ+Nr19EPjsAmb4A+DXprffM+QMffafrrscuA84ASwv4DXYAzwE/Mb0+FULmOEo8J7p7b3A9wae4feB64BvbfD4zcAXgQBvAu4fcv9zeB3MRJmJ6RozUW0zseg89J1hus5MbNNMtD6zNYaPcNh0hqq6t6qenh6eYPIeMVu2/9SHmHxW2DMD7n0uM7wLOFJVTwFU1RMLmKGAl01vvxz4/pADVNV9TP4KaiMHgE/WxAngFUlePeQMmIle+0+ZCTMxO0erTCw6D71mmDIT2zQTrcvWGD7Coc8Ms25h0lq3bP/pachdVfWFAfc9pxmAa4BrknwlyYkk+xYwwx3AO5KcYfJXTe8beIbNnOv3Sqs9zISZeN4dmInOmgaZWHQees1gJn7hDrZhJrb043rGLsk7gGXgLVu450uAjwDv3Ko9N7CDySniG5j81HZfkjdU1U+2cIZDwF1V9Y9Jfo/Je/K8vqr+bwtn0AwzYSb0gkXkYbqvmXjBtsxE6zNb5/IRDmTORzg0noEkNwIfBPZX1c+2cP/LgdcDX07yPSa/A14Z+OLHPq/BGWClqn5eVd8Fvs0kVFs5wy3AMYCq+irwUiafh7VVen2vbMEeZsJMPM9MrFvTIBOLzkOfGczEC7ZnJoa8sOwsF5LtAE4DV/PCxW6/tW7Ne+le+HhsATO8kclFeXsW8RqsW/9lhr/wsc9rsA/4xPT2FUxOk75yi2f4IvDO6e3XMfldfAZ+La5i4wsf/5juhY9fW8T3g5kwEzNrzES1zcSi89B3hnXrzURtr0wM/k1zlsFuZtJ+vwN8cHrfnUx+OoBJK/0csAZ8DXjtAmb4T+B/ga9Pv1a2cv91awcPUc/XIExOU58CvgkcXMAMe4GvTAP2deCPBt7/M8APgJ8z+QntFuDdwLtnXoMj0/m+2eL/oefrYCa6a82EmWiaiUXnoc8M69aaiW2WCd9BXpIkqSHfQV6SJKkhy5YkSVJDli1JkqSGLFuSJEkNWbYkSZIasmxJkiQ1ZNmSJElqyLIlSZLU0P8HxWGHmx2FA24AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 720x720 with 9 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import skfuzzy as fuzz\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "\n",
    "# Set up the loop and plot\n",
    "fig1, axes1 = plt.subplots(3, 3, figsize=(10, 10))\n",
    "fpcs = []\n",
    "\n",
    "for ncenters, ax in enumerate(axes1.reshape(-1), 2):\n",
    "    cntr, u, u0, d, jm, p, fpc = fuzz.cluster.cmeans(\n",
    "        df_clustering, ncenters, 2, error=0.005, maxiter=1000, init=None)\n",
    "\n",
    "    # Store fpc values for later\n",
    "    fpcs.append(fpc)\n",
    "\n",
    "    # Plot assigned clusters, for each data point in training set\n",
    "    cluster_membership = np.argmax(u, axis=0)\n",
    "    for j in range(ncenters):\n",
    "        ax.plot(xpts[cluster_membership == j],\n",
    "                ypts[cluster_membership == j], '.', color=colors[j])\n",
    "\n",
    "    # Mark the center of each fuzzy cluster\n",
    "    for pt in cntr:\n",
    "        ax.plot(pt[0], pt[1], 'rs')\n",
    "\n",
    "    ax.set_title('Centers = {0}; FPC = {1:.2f}'.format(ncenters, fpc), size=12)\n",
    "    ax.axis('off')\n",
    "\n",
    "fig1.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
